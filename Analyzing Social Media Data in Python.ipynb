{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "consumer_key = pd.read_excel(r'E:\\PYTHON\\APIs\\Twitter\\twitter_keys.xlsx')['consumer_key'].values[0]\n",
    "consumer_secret = pd.read_excel(r'E:\\PYTHON\\APIs\\Twitter\\twitter_keys.xlsx')['consumer_secret'].values[0]\n",
    "access_token = pd.read_excel(r'E:\\PYTHON\\APIs\\Twitter\\twitter_keys.xlsx')['access_token'].values[0]\n",
    "access_token_secret = pd.read_excel(r'E:\\PYTHON\\APIs\\Twitter\\twitter_keys.xlsx')['access_token_secret'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "\n",
    " \n",
    "# Consumer key authentication\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# Access key authentication\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Set up the API with the authentication handler\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slistener import SListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "\n",
    "# Set up words to track\n",
    "keywords_to_track = ['#rstats','#python']\n",
    "\n",
    "# Instantiate the SListener object \n",
    "listen = SListener(api)\n",
    "\n",
    "# Instantiate the Stream object\n",
    "stream = Stream(auth, listen)\n",
    "\n",
    "# Begin collecting data\n",
    "stream.filter(track = keywords_to_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = {    \"created_at\": \"Thu Apr 19 14:25:04 +0000 2018\",    \"id\": 986973961295720449,    \"id_str\": \"986973961295720449\",    \"text\": \"Writing out the script of my @DataCamp class and I can\\'t help but mentally read it back to myself in @hugobowne\\'s voice.\",    \"truncated\": False,    \"entities\": {        \"hashtags\": [],        \"symbols\": [],        \"user_mentions\": [{            \"screen_name\": \"DataCamp\",            \"name\": \"DataCamp\",            \"id\": 1568606814,            \"id_str\": \"1568606814\",            \"indices\": [29, 38]        }, {            \"screen_name\": \"hugobowne\",            \"name\": \"Hugo Bowne-Anderson\",            \"id\": 1092509048,            \"id_str\": \"1092509048\",            \"indices\": [101, 111]        }],        \"urls\": []    },    \"metadata\": {        \"iso_language_code\": \"en\",        \"result_type\": \"recent\"    },    \"in_reply_to_status_id\": np.nan,    \"in_reply_to_status_id_str\": np.nan,    \"in_reply_to_user_id\": np.nan,    \"in_reply_to_user_id_str\": np.nan,    \"in_reply_to_screen_name\": np.nan,    \"user\": {        \"id\": 661613,        \"id_str\": \"661613\",        \"name\": \"Alex Hanna, Data Witch\",        \"screen_name\": \"alexhanna\",        \"location\": \"Toronto, ON\",        \"description\": \"Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She\\\\/her.\",        \"url\": \"https:\\\\/\\\\/t.co\\\\/WGddk8Cc6v\",        \"entities\": {            \"url\": {                \"urls\": [{                    \"url\": \"https:\\\\/\\\\/t.co\\\\/WGddk8Cc6v\",                    \"expanded_url\": \"http:\\\\/\\\\/alex-hanna.com\",                    \"display_url\": \"alex-hanna.com\",                    \"indices\": [0, 23]                }]            },            \"description\": {                \"urls\": []            }        },        \"protected\": False,        \"followers_count\": 4267,        \"friends_count\": 2801,        \"listed_count\": 246,        \"created_at\": \"Thu Jan 18 20:37:52 +0000 2007\",        \"favourites_count\": 23387,        \"utc_offset\": -14400,        \"time_zone\": \"Eastern Time (US & Canada)\",        \"geo_enabled\": True,        \"verified\": False,        \"statuses_count\": 71840,        \"lang\": \"en\",        \"contributors_enabled\": False,        \"is_translator\": False,        \"is_translation_enabled\": False,        \"profile_background_color\": \"000000\",        \"profile_background_image_url\": \"http:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme16\\\\/bg.gif\",        \"profile_background_image_url_https\": \"https:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme16\\\\/bg.gif\",        \"profile_background_tile\": False,        \"profile_image_url\": \"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/980799823900180483\\\\/J9CDOX_X_normal.jpg\",        \"profile_image_url_https\": \"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/980799823900180483\\\\/J9CDOX_X_normal.jpg\",        \"profile_banner_url\": \"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/661613\\\\/1514976085\",        \"profile_link_color\": \"0671B8\",        \"profile_sidebar_border_color\": \"666666\",        \"profile_sidebar_fill_color\": \"CCCCCC\",        \"profile_text_color\": \"333333\",        \"profile_use_background_image\": False,        \"has_extended_profile\": False,        \"default_profile\": False,        \"default_profile_image\": False,        \"following\": False,        \"follow_request_sent\": False,        \"notifications\": False,        \"translator_type\": \"regular\"    },    \"geo\": np.nan,    \"coordinates\": np.nan,    \"place\": np.nan,    \"contributors\": np.nan,    \"is_quote_status\": False,    \"retweet_count\": 0,    \"favorite_count\": 1,    \"favorited\": False,    \"retweeted\": False,    \"lang\": \"en\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out the script of my @DataCamp class and I can't help but mentally read it back to myself in @hugobowne's voice.\n",
      "986973961295720449\n"
     ]
    }
   ],
   "source": [
    "# # Load JSON\n",
    "# import json\n",
    "\n",
    "# # Convert from JSON to Python object\n",
    "# tweet = json.loads(tweet_json)\n",
    "\n",
    "# Print tweet text\n",
    "print(tweet['text'])\n",
    "\n",
    "# Print tweet id\n",
    "print(tweet['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexhanna\n",
      "4267\n",
      "Toronto, ON\n",
      "Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She\\/her.\n"
     ]
    }
   ],
   "source": [
    "# Print user handle\n",
    "print(tweet['user']['screen_name'])\n",
    "\n",
    "# Print user follower count\n",
    "print(tweet['user']['followers_count'])\n",
    "\n",
    "# Print user location\n",
    "print(tweet['user']['location'])\n",
    "\n",
    "# Print user description\n",
    "print(tweet['user']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = {'contributors': None,\n",
    " 'coordinates': None,\n",
    " 'created_at': 'Thu Apr 19 12:45:59 +0000 2018',\n",
    " 'entities': {'hashtags': [],\n",
    "  'symbols': [],\n",
    "  'urls': [],\n",
    "  'user_mentions': [{'id': 823957466,\n",
    "    'id_str': '823957466',\n",
    "    'indices': [3, 16],\n",
    "    'name': 'Hanna Wallach',\n",
    "    'screen_name': 'hannawallach'}]},\n",
    " 'favorite_count': 0,\n",
    " 'favorited': False,\n",
    " 'geo': None,\n",
    " 'id': 986949027123154944,\n",
    " 'id_str': '986949027123154944',\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'is_quote_status': False,\n",
    " 'lang': 'en',\n",
    " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
    " 'place': None,\n",
    " 'retweet_count': 37,\n",
    " 'retweeted': False,\n",
    " 'retweeted_status': {'contributors': None,\n",
    "  'coordinates': None,\n",
    "  'created_at': 'Tue Mar 06 23:50:35 +0000 2018',\n",
    "  'entities': {'hashtags': [],\n",
    "   'symbols': [],\n",
    "   'urls': [{'display_url': 'twitter.com/i/web/status/9…',\n",
    "     'expanded_url': 'https://twitter.com/i/web/status/971171213216239616',\n",
    "     'indices': [117, 140],\n",
    "     'url': 'https://t.co/aB9Y5tTyHT'}],\n",
    "   'user_mentions': []},\n",
    "  'favorite_count': 52,\n",
    "  'favorited': False,\n",
    "  'geo': None,\n",
    "  'id': 971171213216239616,\n",
    "  'id_str': '971171213216239616',\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'is_quote_status': False,\n",
    "  'lang': 'en',\n",
    "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
    "  'place': None,\n",
    "  'possibly_sensitive': False,\n",
    "  'retweet_count': 37,\n",
    "  'retweeted': False,\n",
    "  'text': \"ICYMI: NIPS/ICML/ICLR are looking for a full-time programmer to run the conferences' submission/review processes. M… https://t.co/aB9Y5tTyHT\",\n",
    "  'truncated': True,\n",
    "  'user': {'contributors_enabled': False,\n",
    "   'created_at': 'Fri Sep 14 20:38:24 +0000 2012',\n",
    "   'default_profile': False,\n",
    "   'default_profile_image': False,\n",
    "   'description': 'MSR NYC. Machine learning, computational social science, fairness/accountability/transparency in ML. NIPS 2018 program chair, WiML co-founder, sloth enthusiast.',\n",
    "   'entities': {'description': {'urls': []},\n",
    "    'url': {'urls': [{'display_url': 'dirichlet.net',\n",
    "       'expanded_url': 'http://dirichlet.net/',\n",
    "       'indices': [0, 23],\n",
    "       'url': 'https://t.co/hrcIziHrkf'}]}},\n",
    "   'favourites_count': 3507,\n",
    "   'follow_request_sent': False,\n",
    "   'followers_count': 10614,\n",
    "   'following': True,\n",
    "   'friends_count': 865,\n",
    "   'geo_enabled': False,\n",
    "   'has_extended_profile': False,\n",
    "   'id': 823957466,\n",
    "   'id_str': '823957466',\n",
    "   'is_translation_enabled': False,\n",
    "   'is_translator': False,\n",
    "   'lang': 'en',\n",
    "   'listed_count': 499,\n",
    "   'location': 'Brooklyn, NY',\n",
    "   'name': 'Hanna Wallach',\n",
    "   'notifications': False,\n",
    "   'profile_background_color': 'CCCCCC',\n",
    "   'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/521040468528754688/_Ayh3ZCE.jpeg',\n",
    "   'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/521040468528754688/_Ayh3ZCE.jpeg',\n",
    "   'profile_background_tile': False,\n",
    "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/823957466/1347986011',\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/2623320981/kinlr53ma1flkp9jerk4_normal.jpeg',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/2623320981/kinlr53ma1flkp9jerk4_normal.jpeg',\n",
    "   'profile_link_color': '999999',\n",
    "   'profile_sidebar_border_color': 'FFFFFF',\n",
    "   'profile_sidebar_fill_color': 'DDEEF6',\n",
    "   'profile_text_color': '333333',\n",
    "   'profile_use_background_image': False,\n",
    "   'protected': False,\n",
    "   'screen_name': 'hannawallach',\n",
    "   'statuses_count': 1505,\n",
    "   'time_zone': 'Eastern Time (US & Canada)',\n",
    "   'translator_type': 'none',\n",
    "   'url': 'https://t.co/hrcIziHrkf',\n",
    "   'utc_offset': -14400,\n",
    "   'verified': False}},\n",
    " 'text': \"RT @hannawallach: ICYMI: NIPS/ICML/ICLR are looking for a full-time programmer to run the conferences' submission/review processes. More in…\",\n",
    " 'truncated': False,\n",
    " 'user': {'contributors_enabled': False,\n",
    "  'created_at': 'Thu Jan 18 20:37:52 +0000 2007',\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'description': 'Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She/her.',\n",
    "  'entities': {'description': {'urls': []},\n",
    "   'url': {'urls': [{'display_url': 'alex-hanna.com',\n",
    "      'expanded_url': 'http://alex-hanna.com',\n",
    "      'indices': [0, 23],\n",
    "      'url': 'https://t.co/WGddk8Cc6v'}]}},\n",
    "  'favourites_count': 23387,\n",
    "  'follow_request_sent': False,\n",
    "  'followers_count': 4267,\n",
    "  'following': False,\n",
    "  'friends_count': 2801,\n",
    "  'geo_enabled': True,\n",
    "  'has_extended_profile': False,\n",
    "  'id': 661613,\n",
    "  'id_str': '661613',\n",
    "  'is_translation_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'lang': 'en',\n",
    "  'listed_count': 246,\n",
    "  'location': 'Toronto, ON',\n",
    "  'name': 'Alex Hanna, Data Witch',\n",
    "  'notifications': False,\n",
    "  'profile_background_color': '000000',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/661613/1514976085',\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_link_color': '0671B8',\n",
    "  'profile_sidebar_border_color': '666666',\n",
    "  'profile_sidebar_fill_color': 'CCCCCC',\n",
    "  'profile_text_color': '333333',\n",
    "  'profile_use_background_image': False,\n",
    "  'protected': False,\n",
    "  'screen_name': 'alexhanna',\n",
    "  'statuses_count': 71840,\n",
    "  'time_zone': 'Eastern Time (US & Canada)',\n",
    "  'translator_type': 'regular',\n",
    "  'url': 'https://t.co/WGddk8Cc6v',\n",
    "  'utc_offset': -14400,\n",
    "  'verified': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @hannawallach: ICYMI: NIPS/ICML/ICLR are looking for a full-time programmer to run the conferences' submission/review processes. More in…\n",
      "ICYMI: NIPS/ICML/ICLR are looking for a full-time programmer to run the conferences' submission/review processes. M… https://t.co/aB9Y5tTyHT\n",
      "alexhanna\n",
      "hannawallach\n"
     ]
    }
   ],
   "source": [
    "# Print the text of the tweet\n",
    "print(rt['text'])\n",
    "\n",
    "# Print the text of tweet which has been retweeted\n",
    "print(rt['retweeted_status']['text'])\n",
    "\n",
    "# Print the user handle of the tweet\n",
    "print(rt['user']['screen_name'])\n",
    "\n",
    "# Print the user handle of the tweet which has been retweeted\n",
    "print(rt['retweeted_status']['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoted_tweet = {'contributors': None,\n",
    " 'coordinates': None,\n",
    " 'created_at': 'Wed Apr 25 17:20:04 +0000 2018',\n",
    " 'display_text_range': [0, 35],\n",
    " 'entities': {'hashtags': [],\n",
    "  'symbols': [],\n",
    "  'urls': [{'display_url': 'twitter.com/alexhanna/stat…',\n",
    "    'expanded_url': 'https://twitter.com/alexhanna/status/989191655759663105',\n",
    "    'indices': [36, 59],\n",
    "    'url': 'https://t.co/BzbLDz9j6g'}],\n",
    "  'user_mentions': []},\n",
    " 'favorite_count': 0,\n",
    " 'favorited': False,\n",
    " 'filter_level': 'low',\n",
    " 'geo': None,\n",
    " 'id': 989192330832891904,\n",
    " 'id_str': '989192330832891904',\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'is_quote_status': True,\n",
    " 'lang': 'en',\n",
    " 'place': None,\n",
    " 'possibly_sensitive': False,\n",
    " 'quote_count': 0,\n",
    " 'quoted_status': {'contributors': None,\n",
    "  'coordinates': None,\n",
    "  'created_at': 'Wed Apr 25 17:17:23 +0000 2018',\n",
    "  'entities': {'hashtags': [],\n",
    "   'symbols': [],\n",
    "   'urls': [{'display_url': 'twitter.com/i/web/status/9…',\n",
    "     'expanded_url': 'https://twitter.com/i/web/status/989191655759663105',\n",
    "     'indices': [116, 139],\n",
    "     'url': 'https://t.co/MlFg4qFnEC'}],\n",
    "   'user_mentions': []},\n",
    "  'extended_tweet': {'display_text_range': [0, 191],\n",
    "   'entities': {'hashtags': [],\n",
    "    'symbols': [],\n",
    "    'urls': [],\n",
    "    'user_mentions': []},\n",
    "   'full_text': 'O 280 characters, 280 characters! Wherefore art thou 280 characters?\\nDeny thy JSON and refuse thy key.\\nOr, if thou wilt not, be but sworn my love,\\nAnd I’ll no longer be a 140 character tweet.'},\n",
    "  'favorite_count': 1,\n",
    "  'favorited': False,\n",
    "  'filter_level': 'low',\n",
    "  'geo': None,\n",
    "  'id': 989191655759663105,\n",
    "  'id_str': '989191655759663105',\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'is_quote_status': False,\n",
    "  'lang': 'en',\n",
    "  'place': None,\n",
    "  'quote_count': 0,\n",
    "  'reply_count': 1,\n",
    "  'retweet_count': 0,\n",
    "  'retweeted': False,\n",
    "  'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    "  'text': 'O 280 characters, 280 characters! Wherefore art thou 280 characters?\\nDeny thy JSON and refuse thy key.\\nOr, if thou… https://t.co/MlFg4qFnEC',\n",
    "  'truncated': True,\n",
    "  'user': {'contributors_enabled': False,\n",
    "   'created_at': 'Thu Jan 18 20:37:52 +0000 2007',\n",
    "   'default_profile': False,\n",
    "   'default_profile_image': False,\n",
    "   'description': 'Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She/her.',\n",
    "   'favourites_count': 23526,\n",
    "   'follow_request_sent': None,\n",
    "   'followers_count': 4275,\n",
    "   'following': None,\n",
    "   'friends_count': 2806,\n",
    "   'geo_enabled': True,\n",
    "   'id': 661613,\n",
    "   'id_str': '661613',\n",
    "   'is_translator': False,\n",
    "   'lang': 'en',\n",
    "   'listed_count': 246,\n",
    "   'location': 'Toronto, ON',\n",
    "   'name': 'Alex Hanna, Data Witch',\n",
    "   'notifications': None,\n",
    "   'profile_background_color': '000000',\n",
    "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "   'profile_background_tile': False,\n",
    "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/661613/1524231456',\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "   'profile_link_color': '0671B8',\n",
    "   'profile_sidebar_border_color': '666666',\n",
    "   'profile_sidebar_fill_color': 'CCCCCC',\n",
    "   'profile_text_color': '333333',\n",
    "   'profile_use_background_image': False,\n",
    "   'protected': False,\n",
    "   'screen_name': 'alexhanna',\n",
    "   'statuses_count': 71925,\n",
    "   'time_zone': 'Eastern Time (US & Canada)',\n",
    "   'translator_type': 'regular',\n",
    "   'url': 'http://alex-hanna.com',\n",
    "   'utc_offset': -14400,\n",
    "   'verified': False}},\n",
    " 'quoted_status_id': 989191655759663105,\n",
    " 'quoted_status_id_str': '989191655759663105',\n",
    " 'reply_count': 0,\n",
    " 'retweet_count': 0,\n",
    " 'retweeted': False,\n",
    " 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    " 'text': 'maybe if I quote tweet this lil guy https://t.co/BzbLDz9j6g',\n",
    " 'timestamp_ms': '1524676804632',\n",
    " 'truncated': False,\n",
    " 'user': {'contributors_enabled': False,\n",
    "  'created_at': 'Thu Jan 18 20:37:52 +0000 2007',\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'description': 'Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She/her.',\n",
    "  'favourites_count': 23526,\n",
    "  'follow_request_sent': None,\n",
    "  'followers_count': 4275,\n",
    "  'following': None,\n",
    "  'friends_count': 2806,\n",
    "  'geo_enabled': True,\n",
    "  'id': 661613,\n",
    "  'id_str': '661613',\n",
    "  'is_translator': False,\n",
    "  'lang': 'en',\n",
    "  'listed_count': 246,\n",
    "  'location': 'Toronto, ON',\n",
    "  'name': 'Alex Hanna, Data Witch',\n",
    "  'notifications': None,\n",
    "  'profile_background_color': '000000',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/661613/1524231456',\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_link_color': '0671B8',\n",
    "  'profile_sidebar_border_color': '666666',\n",
    "  'profile_sidebar_fill_color': 'CCCCCC',\n",
    "  'profile_text_color': '333333',\n",
    "  'profile_use_background_image': False,\n",
    "  'protected': False,\n",
    "  'screen_name': 'alexhanna',\n",
    "  'statuses_count': 71926,\n",
    "  'time_zone': 'Eastern Time (US & Canada)',\n",
    "  'translator_type': 'regular',\n",
    "  'url': 'http://alex-hanna.com',\n",
    "  'utc_offset': -14400,\n",
    "  'verified': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maybe if I quote tweet this lil guy https://t.co/BzbLDz9j6g\n",
      "O 280 characters, 280 characters! Wherefore art thou 280 characters?\n",
      "Deny thy JSON and refuse thy key.\n",
      "Or, if thou… https://t.co/MlFg4qFnEC\n",
      "O 280 characters, 280 characters! Wherefore art thou 280 characters?\n",
      "Deny thy JSON and refuse thy key.\n",
      "Or, if thou wilt not, be but sworn my love,\n",
      "And I’ll no longer be a 140 character tweet.\n",
      "Toronto, ON\n"
     ]
    }
   ],
   "source": [
    "# Print the tweet text\n",
    "print(quoted_tweet['text'])\n",
    "\n",
    "# Print the quoted tweet text\n",
    "print(quoted_tweet['quoted_status']['text'])\n",
    "\n",
    "# Print the quoted tweet's extended (140+) text\n",
    "print(quoted_tweet['quoted_status']['extended_tweet']['full_text'])\n",
    "\n",
    "# Print the quoted user location\n",
    "print(quoted_tweet['quoted_status']['user']['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the user screen_name in 'user-screen_name'\n",
    "quoted_tweet['user-screen_name'] = quoted_tweet['user']['screen_name']\n",
    "\n",
    "# Store the quoted_status text in 'quoted_status-text'\n",
    "quoted_tweet['quoted_status-text'] = quoted_tweet['quoted_status']['text']\n",
    "\n",
    "# Store the quoted tweet's extended (140+) text in \n",
    "# 'quoted_status-extended_tweet-full_text'\n",
    "quoted_tweet['quoted_status-extended_tweet-full_text'] = quoted_tweet['quoted_status']['extended_tweet']['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tweets(tweets_json):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON\n",
    "        is in a top-level dictionary.\"\"\"\n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet in tweets_json:\n",
    "        tweet_obj = json.loads(tweet)\n",
    "    \n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "    \n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = tweet_obj['extended_tweet']['full_text']\n",
    "    \n",
    "        if 'retweeted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in 'retweeted_status-user-screen_name'\n",
    "            tweet_obj['retweeted_status-user-screen_name'] = tweet_obj['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['retweeted_status-text'] = tweet_obj['retweeted_status']['text']\n",
    "            \n",
    "        tweets_list.append(tweet_obj)\n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the tweets and store in `tweets`\n",
    "tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Create a DataFrame from `tweets`\n",
    "ds_tweets = pd.DataFrame(tweets)\n",
    "\n",
    "# Print out the first 5 tweets from this dataset\n",
    "print(ds_tweets['text'].values[0:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Flatten the tweets and store them\n",
    "flat_tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ds_tweets = pd.DataFrame(flat_tweets)\n",
    "\n",
    "# Find mentions of #python in 'text'\n",
    "python = ds_tweets['text'].str.contains('#python', case = False)\n",
    "\n",
    "# Print proportion of tweets mentioning #python\n",
    "print(\"Proportion of #python tweets:\", np.sum(python) / ds_tweets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_in_tweet(word, data):\n",
    "    \"\"\"Checks if a word is in a Twitter dataset's text. \n",
    "    Checks text and extended tweet (140+ character tweets) for tweets,\n",
    "    retweets and quoted tweets.\n",
    "    Returns a logical pandas Series.\n",
    "    \"\"\"\n",
    "    contains_column = data['text'].str.contains(word, case = False)\n",
    "    contains_column |= data['extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-text'].str.contains(word, case = False) \n",
    "    contains_column |= data['quoted_status-extended_tweet-full_text'].str.contains(word, case = False) \n",
    "    contains_column |= data['retweeted_status-text'].str.contains(word, case = False) \n",
    "    contains_column |= data['retweeted_status-extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    return contains_column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Find mentions of #python in all text fields\n",
    "python = check_word_in_tweet('#python', ds_tweets)\n",
    "\n",
    "# Find mentions of #rstats in all text fields\n",
    "rstats = check_word_in_tweet('#rstats', ds_tweets)\n",
    "\n",
    "# Print proportion of tweets mentioning #python\n",
    "print(\"Proportion of #python tweets:\", np.sum(python) / ds_tweets.shape[0])\n",
    "\n",
    "# Print proportion of tweets mentioning #rstats\n",
    "print(\"Proportion of #rstats tweets:\", np.sum(rstats) / ds_tweets.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print created_at to see the original format of datetime in Twitter data\n",
    "print(ds_tweets['created_at'].head())\n",
    "\n",
    "# Convert the created_at column to np.datetime object\n",
    "ds_tweets['created_at'] = pd.to_datetime(ds_tweets['created_at'])\n",
    "\n",
    "# Print created_at to see new format\n",
    "print(ds_tweets['created_at'].head())\n",
    "\n",
    "# Set the index of ds_tweets to created_at\n",
    "ds_tweets = ds_tweets.set_index('created_at')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a python column\n",
    "ds_tweets['python'] = check_word_in_tweet('#python', ds_tweets)\n",
    "\n",
    "# Create an rstats column\n",
    "ds_tweets['rstats'] = check_word_in_tweet('#rstats', ds_tweets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Average of python column by day\n",
    "mean_python = ds_tweets['python'].resample('1 d').mean()\n",
    "\n",
    "# Average of rstats column by day\n",
    "mean_rstats = ds_tweets['rstats'].resample('1 d').mean()\n",
    "\n",
    "# Plot mean python/rstats by day\n",
    "plt.plot(mean_python.index.day, mean_python, color = 'green')\n",
    "plt.plot(mean_rstats.index.day, mean_rstats, color = 'blue')\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel('Day'); plt.ylabel('Frequency')\n",
    "plt.title('Language mentions over time')\n",
    "plt.legend(('#python', '#rstats'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = ds_tweets['text'].apply(sid.polarity_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print out the text of a positive tweet\n",
    "print(ds_tweets[sentiment > 0.6]['text'].values[0])\n",
    "\n",
    "# Print out the text of a negative tweet\n",
    "print(ds_tweets[sentiment < -0.6]['text'].values[0])\n",
    "\n",
    "# Generate average sentiment scores for #python\n",
    "sentiment_py = sentiment[ check_word_in_tweet('#python', ds_tweets) ].resample('1 d').mean()\n",
    "\n",
    "# Generate average sentiment scores for #rstats\n",
    "sentiment_r = sentiment[ check_word_in_tweet('#rstats', ds_tweets) ].resample('1 d').mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot average #python sentiment per day\n",
    "plt.plot(sentiment_py.index.day, sentiment_py, color = 'green')\n",
    "\n",
    "# Plot average #rstats sentiment per day\n",
    "plt.plot(sentiment_r.index.day, sentiment_r, color = 'blue')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment of data science languages')\n",
    "plt.legend(('#python', '#rstats'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import networkx\n",
    "import networkx as nx\n",
    "\n",
    "# Create retweet network from edgelist\n",
    "G_rt = nx.from_pandas_edgelist(\n",
    "    sotu_retweets,\n",
    "    source = 'user-screen_name', \n",
    "    target = 'retweeted_status-user-screen_name',\n",
    "    create_using = nx.DiGraph())\n",
    "    \n",
    "# Print the number of nodes\n",
    "print('Nodes in RT network:', len(G_rt.nodes()))\n",
    "\n",
    "# Print the number of edges\n",
    "print('Edges in RT network:', len(G_rt.edges()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import networkx\n",
    "import networkx as nx\n",
    "\n",
    "# Create reply network from edgelist\n",
    "G_reply = nx.from_pandas_edgelist(\n",
    "    sotu_replies,\n",
    "    source = 'user-screen_name', \n",
    "    target = 'in_reply_to_screen_name',\n",
    "    create_using = nx.DiGraph())\n",
    "    \n",
    "# Print the number of nodes\n",
    "print('Nodes in reply network:', len(G_reply.nodes()))\n",
    "\n",
    "# Print the number of edges\n",
    "print('Edges in reply network:', len(G_reply.edges()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create random layout positions\n",
    "pos = nx.random_layout(G_rt)\n",
    "\n",
    "# Create size list\n",
    "sizes = [x[1] for x in G_rt.degree()]\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx(G_rt, pos, \n",
    "    with_labels = False, \n",
    "    node_size = sizes,\n",
    "    width = 0.1, alpha = 0.7,\n",
    "    arrowsize = 2, linewidths = 0)\n",
    "\n",
    "# Turn axis off and show\n",
    "plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate in-degree centrality for retweets \n",
    "rt_centrality = nx.in_degree_centrality(G_rt)\n",
    "\n",
    "# Generate in-degree centrality for replies \n",
    "reply_centrality = nx.in_degree_centrality(G_reply)\n",
    "\n",
    "# Store centralities in DataFrame\n",
    "rt = pd.DataFrame(list(rt_centrality.items()), columns = column_names)\n",
    "reply = pd.DataFrame(list(reply_centrality.items()), columns = column_names)\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(rt.sort_values('degree_centrality', ascending = False).head())\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(reply.sort_values('degree_centrality', ascending = False).head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate betweenness centrality for retweets \n",
    "rt_centrality = nx.betweenness_centrality(G_rt)\n",
    "\n",
    "# Generate betweenness centrality for replies \n",
    "reply_centrality = nx.betweenness_centrality(G_reply)\n",
    "\n",
    "# Store centralities in data frames\n",
    "rt = pd.DataFrame(list(rt_centrality.items()), columns = column_names)\n",
    "reply = pd.DataFrame(list(reply_centrality.items()), columns = column_names)\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(rt.sort_values('betweenness_centrality', ascending = False).head())\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(reply.sort_values('betweenness_centrality', ascending = False).head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate in-degrees and store in DataFrame\n",
    "degree_rt = pd.DataFrame(list(G_rt.in_degree()), columns = column_names)\n",
    "degree_reply = pd.DataFrame(list(G_reply.in_degree()), columns = column_names)\n",
    "\n",
    "# Merge the two DataFrames on screen name\n",
    "ratio = degree_rt.merge(degree_reply, on = 'screen_name', suffixes = ('_rt', '_reply'))\n",
    "\n",
    "# Calculate the ratio\n",
    "ratio['ratio'] = ratio['degree_reply'] / ratio['degree_rt']\n",
    "\n",
    "# Exclude any tweets with less than 5 retweets\n",
    "ratio = ratio[ratio['degree_rt'] >= 5]\n",
    "\n",
    "# Print out first five with highest ratio\n",
    "print(ratio.sort_values('ratio', ascending = False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map and Twitter Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print out the location of a single tweet\n",
    "print(tweet_json['user']['location'])\n",
    "\n",
    "# Flatten and load the SOTU tweets into a dataframe\n",
    "tweets_sotu = pd.DataFrame(flatten_tweets(tweets_sotu_json))\n",
    "\n",
    "# Print out top five user-defined locations\n",
    "print(tweets_sotu['user-location'].value_counts().head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getBoundingBox(place):\n",
    "    \"\"\" Returns the bounding box coordinates.\"\"\"\n",
    "    return place['bounding_box']['coordinates']\n",
    "\n",
    "# Apply the function which gets bounding box coordinates\n",
    "bounding_boxes = tweets_sotu['place'].apply(getBoundingBox)\n",
    "\n",
    "# Print out the first bounding box coordinates\n",
    "print(bounding_boxes.values[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calculateCentroid(place):\n",
    "    \"\"\" Calculates the centroid from a bounding box.\"\"\"\n",
    "    # Obtain the coordinates from the bounding box.\n",
    "    coordinates = place['bounding_box']['coordinates'][0]\n",
    "    \n",
    "    longs = np.unique( [x[0] for x in coordinates] )\n",
    "    lats  = np.unique( [x[1] for x in coordinates] )\n",
    "    \n",
    "    if len(longs) == 1 and len(lats) == 1:\n",
    "        # return a single coordinate\n",
    "        return (longs[0], lats[0])\n",
    "    elif len(longs) == 2 and len(lats) == 2:\n",
    "        # If we have two longs and lats, we have a box.\n",
    "        central_long = np.sum(longs) / 2\n",
    "        central_lat  = np.sum(lats) / 2\n",
    "    else:\n",
    "        raise ValueError(\"Non-rectangular polygon not supported.\")\n",
    "\n",
    "    return (central_long, central_lat)\n",
    "\n",
    "# Calculate the centroids of place     \n",
    "centroids = tweets_sotu['place'].apply(calculateCentroid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import Basemap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the US bounding box\n",
    "us_boundingbox = [-125, 22, -64, 50] \n",
    "\n",
    "# Set up the Basemap object\n",
    "m = Basemap(llcrnrlon = us_boundingbox[0],\n",
    "            llcrnrlat = us_boundingbox[1],\n",
    "            urcrnrlon = us_boundingbox[2],\n",
    "            urcrnrlat = us_boundingbox[3],\n",
    "            projection='merc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import Basemap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the US bounding box\n",
    "us_boundingbox = [-125, 22, -64, 50] \n",
    "\n",
    "# Set up the Basemap object\n",
    "m = Basemap(llcrnrlon = us_boundingbox[0],\n",
    "            llcrnrlat = us_boundingbox[1],\n",
    "            urcrnrlon = us_boundingbox[2],\n",
    "            urcrnrlat = us_boundingbox[3],\n",
    "            projection='merc')\n",
    "\n",
    "# Draw continents in white, \n",
    "# coastlines and countries in gray\n",
    "m.fillcontinents(color='white')\n",
    "m.drawcoastlines(color='gray')\n",
    "m.drawcountries(color='gray')\n",
    "\n",
    "# Draw the states and show the plot\n",
    "m.drawstates(color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate the centroids for the dataset \n",
    "# and isolate longitudue and latitudes\n",
    "centroids = tweets_sotu['place'].apply(calculateCentroid)\n",
    "lon = [x[0] for x in centroids]\n",
    "lat = [x[1] for x in centroids]\n",
    "\n",
    "# Draw continents, coastlines, countries, and states\n",
    "m.fillcontinents(color='white', zorder = 0)\n",
    "m.drawcoastlines(color='gray')\n",
    "m.drawcountries(color='gray')\n",
    "m.drawstates(color='gray')\n",
    "\n",
    "# Draw the points and show the plot\n",
    "m.scatter(lon, lat, latlon = True, alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate sentiment scores\n",
    "sentiment_scores = tweets_sotu['text'].apply(sid.polarity_scores)\n",
    "\n",
    "# Isolate the compound element\n",
    "sentiment_scores = [x['compound'] for x in sentiment_scores]\n",
    "\n",
    "# Draw the points\n",
    "m.scatter(lon, lat, latlon = True, \n",
    "           c = sentiment_scores,\n",
    "           cmap = 'coolwarm', alpha = 0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
