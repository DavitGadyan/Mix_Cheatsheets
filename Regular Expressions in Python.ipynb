{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = '$I supposed that coming from MTV Films I should expect no less$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n",
      "i supposed that coming from mtv films i should expect no less\n",
      "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n",
      "suppose\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)\n",
    "\n",
    "# Remove whitespaces and print the result\n",
    "movie_no_space = movie_lower.strip(\"$\")\n",
    "print(movie_no_space)\n",
    "\n",
    "# Split the string into substrings and print the result\n",
    "movie_split = movie_no_space.split()\n",
    "print(movie_split)\n",
    "\n",
    "# Select root word and print the result\n",
    "word_root = movie_split[1][:-1]\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = 'the film,however,is all good<\\\\i>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film,however,is all good\n",
      "['the film', 'however', 'is all good']\n",
      "the film however is all good\n"
     ]
    }
   ],
   "source": [
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.rstrip(\"<\\i>\")\n",
    "print(movie_tag)\n",
    "\n",
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(\",\")\n",
    "print(movie_no_comma)\n",
    "\n",
    "# Join back together and print results\n",
    "movie_join = ' '.join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example']\n",
      "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "# Split string at line boundaries\n",
    "file_split = file.split('\\n')\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(',')\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mtv films election, a high school comedy, is a current example',\n",
       " 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.splitlines()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for movie in movies:\n",
    "  \t# Find if actor occurrs between 37 and 41 inclusive\n",
    "    if movie.find(\"actor\", 37, 42) == -1:\n",
    "        print(\"Word not found\")\n",
    "    # Count occurrences and replace two by one\n",
    "    elif movie.count(\"actor\") == 2:  \n",
    "        print(movie.replace(\"actor actor\", \"actor\"))\n",
    "    else:\n",
    "        # Replace three occurrences by one\n",
    "        print(movie.replace(\"actor actor actor\", \"actor\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for movie in movies:\n",
    "  # Find the first occurrence of word\n",
    "  print(movie.find(\"money\", 12, 51))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Replace negations \n",
    "movies_no_negation = movies.replace(\"isn't\", \"is\")\n",
    "\n",
    "# Replace important\n",
    "movies_antonym = movies_no_negation.replace(\"important\", \"insignificant\")\n",
    "\n",
    "# Print out\n",
    "print(movies_antonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_article = 'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tool computer science is used in artificial intelligence\n",
      "The tool computer science is used in artificial intelligence\n",
      "The tool artificial intelligence is used in computer science\n"
     ]
    }
   ],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")\n",
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"The tool {1} is used in {0}\")\n",
    "\n",
    "# Use format to print strings\n",
    "for my_string in my_list:\n",
    "  \tprint(my_string.format(first_pos, second_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = ['artificial intelligence', 'neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary\n",
    "plan = {\n",
    "        \"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "        }\n",
    "\n",
    "# Define string with placeholders\n",
    "my_message = \"If you are interested in {}, you can take the course related to {}\"\n",
    "\n",
    "# Use dictionary to replace placehoders\n",
    "print(my_message.format(plan['field'],plan['tool']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is October 06, 2019. It's 20:30 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "from  datetime import datetime\n",
    "\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Format date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "field1 = 'sexiest job'\n",
    "fact1 = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered 'sexiest job' in the 21st century\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"Data science is considered {field1!r} in the {fact1:d}st century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact2 = 2.500000e+18\n",
    "field2 = 'is produced daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 2.500000e+18 of is produced daily in the world\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"About {fact2:e} of {field2} in the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "field3 = 'Individuals' \n",
    "fact3 = 72.41\n",
    "fact4 = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals create around 72.41% of the data but only 1.1% is analyzed\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"{field3} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "number1 = 120\n",
    "number2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
     ]
    }
   ],
   "source": [
    "# Include both variables and the result of dividing them \n",
    "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {number1/number2:.1f} tweets per min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'https www.datacamp.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " www.datacamp.com\n"
     ]
    }
   ],
   "source": [
    "# Replace the substring https by an empty string\n",
    "print(f\"{string1.replace('https', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_links = ['www.news.com',\n",
    " 'www.google.com',\n",
    " 'www.yahoo.com',\n",
    " 'www.bbc.com',\n",
    " 'www.msn.com',\n",
    " 'www.facebook.com',\n",
    " 'www.news.google.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 5.83% of the posts contain links\n"
     ]
    }
   ],
   "source": [
    "# Divide the length of list by 120 rounded to two decimals\n",
    "print(f\"Only {len(list_links)*100/120:.2f}% of the posts contain links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "east = {'date': datetime(2007, 4, 20, 0, 0), 'price': 1232443}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
     ]
    }
   ],
   "source": [
    "# Access values of date and price in east dictionary\n",
    "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "west = {'date': datetime(2006, 5, 26, 0, 0), 'price': 1432673}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the west neighborhood was $1432673 in 05-26-2006.\n"
     ]
    }
   ],
   "source": [
    "# Access values of date and price in west dictionary\n",
    "print(f\"The price for a house in the west neighborhood was ${west['price']} in {west['date']:%m-%d-%Y}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import Template\n",
    "from string import Template\n",
    "\n",
    "# Create a template\n",
    "wikipedia = Template(\"$tool is a $description\")\n",
    "\n",
    "# Substitute variables in template\n",
    "print(wikipedia.substitute(tool=tool1, description=description1))\n",
    "print(wikipedia.substitute(tool=tool2, description=description2))\n",
    "print(wikipedia.substitute(tool=tool3, description=description3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Select variables\n",
    "our_tool = tools[0]\n",
    "our_fee = tools[1]\n",
    "our_pay = tools[2]\n",
    "\n",
    "# Create template\n",
    "course = Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
    "\n",
    "# Substitute identifiers with three variables\n",
    "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Complete template string using identifiers\n",
    "the_answers = Template(\"Check your answer 1: $answer1, and your answer 2: $answer2\")\n",
    "\n",
    "# Use safe_substitute to replace identifiers\n",
    "try:\n",
    "    print(the_answers.safe_substitute(answers))\n",
    "except KeyError:\n",
    "    print(\"Missing information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = '@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is in love with scrappy.  He is missing him already\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, ' ', sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\n",
    "\"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",\n",
    "\"im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "[]\n",
      "['@anitaLopez98', '@MyredHat31']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany', '@foxRadio']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re \n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"https://\\S+\", tweet))\n",
    "\n",
    "# \t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39 Internet keeps']\n",
      "['31 which affected']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\s+\\w+\\s+\\w+\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, '', sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\n",
    "\"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIshadowhunters.txt']\n",
      " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
      "['ouMYTAXES.txt']\n",
      " I am worried that I won't get my $900 even though I paid tax last year\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"^[a-zA-Z]{1,20}\\.txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))\n",
    "    \n",
    "\t# Replace all matches with empty string\n",
    "\tprint(re.sub(regex, '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "  \t# Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "      \tprint(\"The email {email_example} is invalid\".format(email_example=example))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = ['Apple34!rose', 'My87hou#4$', 'abc123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]{8,20}\" \n",
    "\n",
    "for example in passwords:\n",
    "  \t# Scan the strings to find a match\n",
    "    if re.search(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'I want to see that <strong>amazing show</strong> again!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing show again!\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '6', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression \n",
    "numbers_found_lazy = re.findall(r\"\\d+?\", 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left ')\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536', '12']\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression \n",
    "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying). \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' (They were so cute) ', \" (I'm crying).\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression to match \n",
    "sentences_found_greedy = re.findall(r\"\\s\\(.+\\){1}\\s|\\s\\(.+\\){1}\\.\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(sentences_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression\n",
    "sentences_found_lazy = re.findall(r\"\\(.*?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well done! Notice that using greedy quantifiers always leads to longer matches that sometimes are not desired. Making quantifiers lazy by adding ? to match a shorter pattern is a very important consideration to keep in mind when handling data for text mining. Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"\\s([a-zA-Z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['U', 'o']\n",
      "Lists of users found in this tweet: ['4']\n",
      "Lists of users found in this tweet: ['8']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"\\s([a-zA-Z0-9])+@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IB', '3723', 'AMS', 'MAD', '06OCT')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "    \n",
    "#Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r\"(love|like|enjoy).+(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    " 'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'The cabin and the ant')]\n",
      "Negative comments found [('disapprove', 'Honest with you')]\n",
      "Negative comments found [('dislike', 'After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Provider’s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Signed on 03/25/2001'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"(?:Signed\\son\\s)(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Signed on 03/25/2001'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "\t\"day\": dates.group(2),\n",
    "\t\"month\": dates.group(1),\n",
    "\t\"year\": dates.group(3)\n",
    "}\n",
    "# Complete the format method to print-out\n",
    "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
    " '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
    " '<nav>About me Links Contact me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Your tag article is closed\n",
      "Close your nav tag!\n"
     ]
    }
   ],
   "source": [
    "for string in html_tags:\n",
    "    # Complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag =  re.match(r\"<(\\w+)>.*?</\\1>\", string)\n",
    " \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print(\"Your tag {} is closed\".format(match_tag.group(1))) \n",
    "    else:\n",
    "        # If it doesn't match capture only the tag \n",
    "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
    "        # Print the first group capture\n",
    "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    " 'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    }
   ],
   "source": [
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r\"\\w*(\\w)\\1\\w*\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find if there is a match in each tweet \n",
    "\tmatch_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "\tif match_elongated:\n",
    "\t\t# Assign the captured group zero \n",
    "\t\telongated_word = match_elongated.group(0)\n",
    "        \n",
    "\t\t# Complete the format method to print the word\n",
    "\t\tprint(\"Elongated word found: {word}\".format(word=elongated_word))\n",
    "\telse:\n",
    "\t\tprint(\"No elongated word found\")     \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive lookahead (?=) makes sure that first part of the expression is followed by the lookahead expression. Positive lookbehind (?<=) returns all matches that are preceded by the specified pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookahead\n",
    "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookbehind\n",
    "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones = ['4564-646464-01', '345-5785-544245', '6476-579052-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not preceded by area code\n",
    "\tnumber = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "\tprint(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not followed by optional extension\n",
    "\tnumber = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "\tprint(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
